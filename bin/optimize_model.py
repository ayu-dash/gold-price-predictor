import os
import sys
import logging
import numpy as np
import pandas as pd
import ta
from pathlib import Path
from sklearn.model_selection import TimeSeriesSplit, RandomizedSearchCV
from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, make_scorer
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import make_pipeline
import joblib

# Add project root to path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

import config
from core.features import engineering

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')
logger = logging.getLogger(__name__)

def load_data():
    """Load and prepare data for optimization."""
    logger.info("Loading data...")
    if not os.path.exists(config.CSV_PATH):
        logger.error(f"Data file not found: {config.CSV_PATH}")
        sys.exit(1)
        
    df = pd.read_csv(config.CSV_PATH, parse_dates=['Date'], index_col='Date')
    df.index.name = 'Datetime'
    
    # Feature Engineering
    logger.info("Applying feature engineering...")
    df = engineering.add_technical_indicators(df)
    
    # Add advanced features for optimization (Close-only)
    # Since we don't have High/Low, we use Volatility and Momentum based on Close
    df['ROC_10'] = ta.momentum.roc(df['Gold'], window=10)
    df['ROC_20'] = ta.momentum.roc(df['Gold'], window=20)
    df['TRIX'] = ta.trend.trix(df['Gold'], window=15)
    
    # Rolling stats
    df['Rolling_Mean_5'] = df['Gold_Returns'].rolling(window=5).mean()
    df['Rolling_Std_5'] = df['Gold_Returns'].rolling(window=5).std()
    df['Rolling_Mean_10'] = df['Gold_Returns'].rolling(window=10).mean()
    df['Rolling_Std_10'] = df['Gold_Returns'].rolling(window=10).std()
    
    # Verify features
    required_features = [
        'Gold', 'USD_IDR', 'DXY', 'Oil', 'SP500', 'NASDAQ', 'VIX_Norm', 'GVZ_Norm',
        'Silver', 'Copper', 'Platinum', 'Palladium', 'USD_CNY', 'US10Y', 'Nikkei', 'DAX',
        'SMA_7', 'SMA_14', 'RSI', 'RSI_7', 'MACD', 'BB_Width', 'Sentiment',
        'Return_Lag1', 'Return_Lag2', 'Return_Lag3', 'RSI_Lag1', 'Volatility_5', 'Momentum_5',
        'ROC_10', 'ROC_20', 'TRIX', 
        'Rolling_Mean_5', 'Rolling_Std_5', 'Rolling_Mean_10', 'Rolling_Std_10'
    ]
    
    missing = [f for f in required_features if f not in df.columns]
    if missing:
        logger.warning(f"Missing features: {missing}. Computing them now if possible or proceeding without.")
        # Remove missing from required features to avoid error
        required_features = [f for f in required_features if f not in missing]
    
    # cleaning
    df = df.dropna()
    
    # Target Strategy: High Conviction Only
    # Only label as UP (1) if return > 0.0005 (0.05%)
    # Only label as DOWN (0) if return < -0.0005 (-0.05%)
    # Drop rows in between (Noise) for training the classifier
    threshold = 0.0005
    df['Future_Return'] = df['Gold'].shift(-1).pct_change()
    
    # Filter for significant moves
    df_significant = df[abs(df['Future_Return']) > threshold].copy()
    df_significant['Target'] = (df_significant['Future_Return'] > 0).astype(int)
    
    logger.info(f"Original samples: {len(df)}. Significant samples (>{threshold:.2%}): {len(df_significant)}")
    
    valid_features = [f for f in required_features if f in df_significant.columns]
    
    return df_significant[valid_features], df_significant['Target']

def optimize_model(X, y):
    """Run proper time-series cross-validation to find best model."""
    logger.info(f"Starting optimization on {len(X)} samples with {X.shape[1]} features...")
    
    # Time Series Split (Strictly Train on Past, Test on Future)
    tscv = TimeSeriesSplit(n_splits=5)
    
    # 1. HistGradientBoostingClassifier (LightGBM-like, usually best for tabular)
    logger.info("Optimizing HistGradientBoostingClassifier...")
    hgb_param_dist = {
        'learning_rate': [0.01, 0.03, 0.05, 0.1],
        'max_iter': [100, 200, 300, 500],
        'max_depth': [3, 5, 8, 10, None],
        'l2_regularization': [0.0, 0.1, 1.0],
        'min_samples_leaf': [10, 20, 50]
    }
    
    hgb = HistGradientBoostingClassifier(random_state=42, early_stopping=True)
    hgb_search = RandomizedSearchCV(
        hgb, hgb_param_dist, cv=tscv, scoring='accuracy', n_iter=20, n_jobs=-1, random_state=42, verbose=1
    )
    hgb_search.fit(X, y)
    logger.info(f"Best HGB Score: {hgb_search.best_score_:.4f}")
    logger.info(f"Best HGB Params: {hgb_search.best_params_}")
    
    # 2. Random Forest (Robust baseline)
    logger.info("Optimizing RandomForestClassifier...")
    rf_param_dist = {
        'n_estimators': [100, 300, 500],
        'max_depth': [5, 10, 20, None],
        'min_samples_split': [2, 5, 10],
        'min_samples_leaf': [1, 2, 4],
        'max_features': ['sqrt', 'log2']
    }
    
    rf = RandomForestClassifier(random_state=42, n_jobs=-1, class_weight='balanced')
    rf_search = RandomizedSearchCV(
        rf, rf_param_dist, cv=tscv, scoring='accuracy', n_iter=20, n_jobs=-1, random_state=42, verbose=1
    )
    rf_search.fit(X, y)
    logger.info(f"Best RF Score: {rf_search.best_score_:.4f}")
    
    # Select Winner
    if hgb_search.best_score_ >= rf_search.best_score_:
        best_model = hgb_search.best_estimator_
        best_score = hgb_search.best_score_
        model_name = "HistGradientBoosting"
    else:
        best_model = rf_search.best_estimator_
        best_score = rf_search.best_score_
        model_name = "RandomForest"
        
    logger.info(f"\nüèÜ CHAMPION MODEL: {model_name}")
    logger.info(f"Base Validation Accuracy: {best_score:.2%}")
    
    # 3. Threshold Optimization (The "Sniper" Logic)
    logger.info("Searching for high-confidence threshold to hit >75% accuracy...")
    best_model.fit(X, y) # Fit on all data to find threshold
    probs = best_model.predict_proba(X)[:, 1]
    
    best_thresh = 0.5
    best_metrics = {'acc': 0.0, 'prec': 0.0, 'rec': 0.0, 'f1': 0.0}
    coverage = 0.0
    
    # Granular search for threshold
    for t in np.arange(0.5, 0.95, 0.01):
        # Decisions made only when prob > t (UP) or prob < 1-t (DOWN)
        mask = (probs > t) | (probs < (1 - t))
        if sum(mask) < 20: # Minimum samples to be significant
            continue
            
        # Predict: 1 if prob > t, 0 if prob < 1-t
        preds_filtered = (probs[mask] > 0.5).astype(int)
        y_filtered = y[mask]
        
        acc = accuracy_score(y_filtered, preds_filtered)
        
        # We prioritize Accuracy/Precision > 75%
        if acc > best_metrics['acc']:
            best_metrics['acc'] = acc
            best_metrics['prec'] = precision_score(y_filtered, preds_filtered, zero_division=0)
            best_metrics['rec'] = recall_score(y_filtered, preds_filtered, zero_division=0)
            best_metrics['f1'] = f1_score(y_filtered, preds_filtered, zero_division=0)
            best_thresh = t
            coverage = sum(mask) / len(mask)
            
    logger.info(f"\nüéØ OPTIMIZATION RESULTS")
    logger.info(f"Optimal Threshold: {best_thresh:.2f}")
    logger.info(f"Trades Taken: {coverage:.1%} of days")
    logger.info("-" * 30)
    logger.info(f"Accuracy : {best_metrics['acc']:.2%}")
    logger.info(f"Precision: {best_metrics['prec']:.2%}")
    logger.info(f"Recall   : {best_metrics['rec']:.2%}")
    logger.info(f"F1 Score : {best_metrics['f1']:.2%}")
    logger.info("-" * 30)
    
    if best_metrics['acc'] > 0.75:
        logger.info("‚úÖ GOAL ACHIEVED: Accuracy > 75%!")
    else:
        logger.info(f"‚ö†Ô∏è Top accuracy {best_metrics['acc']:.1%} is below 75% target.")

    return best_model, best_metrics['acc'], model_name, best_thresh

def main():
    X, y = load_data()
    
    # Deep Search Loop
    # In a real scenario this might run for hours. Here we run a more intensive single pass.
    # Future enhancement: Wrap optimize_model inside a loop if needed.
    best_model, score, name, thresh = optimize_model(X, y)
    
    # Save the best model
    save_path = config.MODEL_CLASSIFIER_PATH
    logger.info(f"Saving best model to {save_path}...")
    
    # Ensure directory exists
    os.makedirs(os.path.dirname(save_path), exist_ok=True)
    
    # Save model and metadata (threshold)
    # We can save a dictionary or just the model. 
    # For compatibility with predictor.py which expects just the model object,
    # we will just save the model. The threshold is hardcoded/printed for now.
    import pickle
    with open(save_path, 'wb') as f:
        pickle.dump(best_model, f)
        
    logger.info("Optimization Completed Successfully.")
    logger.info(f"Please update predictor.py with Threshold: {thresh:.2f}")

if __name__ == "__main__":
    main()
